{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% -------- 1. Imports & Configuration --------\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import joblib\n",
    "import seaborn as sns\n",
    "from skimage import io, feature\n",
    "from skimage.filters import gabor\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import (classification_report, confusion_matrix,\n",
    "                           roc_curve, roc_auc_score, accuracy_score)\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% -------- 2. Configuration --------\n",
    "IMG_SIZE = (650, 325)  # Reduced size for computational efficiency\n",
    "TARGET_NAMES = ['female', 'male']\n",
    "DATA_PATHS = {\n",
    "    'train': \"D:\\\\level4__semester1\\\\AI-Based\\\\AI-Driven Gender Classification Using Panoramic Dental X-Rays\\\\Radiographs\\\\train\",\n",
    "    'valid': \"D:\\\\level4__semester1\\\\AI-Based\\\\AI-Driven Gender Classification Using Panoramic Dental X-Rays\\\\Radiographs\\\\val\",\n",
    "    'test': \"D:\\\\level4__semester1\\\\AI-Based\\\\AI-Driven Gender Classification Using Panoramic Dental X-Rays\\\\Radiographs\\\\test\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% -------- 2. Metaheuristic Feature Selectors --------\n",
    "class PSOFeatureSelector:\n",
    "    def __init__(self, n_particles=20, iterations=50, phi1=1.5, phi2=1.5):\n",
    "        self.n_particles = n_particles\n",
    "        self.iterations = iterations\n",
    "        self.phi1 = phi1\n",
    "        self.phi2 = phi2\n",
    "        self.best_features = None\n",
    "        \n",
    "    def optimize(self, X, y):\n",
    "        n_features = X.shape[1]\n",
    "        particles = np.random.rand(self.n_particles, n_features)\n",
    "        velocities = np.zeros_like(particles)\n",
    "        pbest = particles.copy()\n",
    "        pbest_scores = np.zeros(self.n_particles)\n",
    "        gbest = None\n",
    "        gbest_score = 0\n",
    "        \n",
    "        for i in range(self.n_particles):\n",
    "            score = self._fitness(X, y, particles[i])\n",
    "            pbest_scores[i] = score\n",
    "            if score > gbest_score:\n",
    "                gbest_score = score\n",
    "                gbest = particles[i].copy()\n",
    "                \n",
    "        for _ in range(self.iterations):\n",
    "            for i in range(self.n_particles):\n",
    "                r1, r2 = np.random.rand(2)\n",
    "                velocities[i] += self.phi1*r1*(pbest[i] - particles[i]) + \\\n",
    "                                self.phi2*r2*(gbest - particles[i])\n",
    "                particles[i] = 1/(1+np.exp(-velocities[i]))\n",
    "                \n",
    "                score = self._fitness(X, y, particles[i])\n",
    "                if score > pbest_scores[i]:\n",
    "                    pbest_scores[i] = score\n",
    "                    pbest[i] = particles[i].copy()\n",
    "                    if score > gbest_score:\n",
    "                        gbest_score = score\n",
    "                        gbest = particles[i].copy()\n",
    "                        \n",
    "        self.best_features = gbest > 0.5\n",
    "        return self.best_features\n",
    "    \n",
    "    def _fitness(self, X, y, particle):\n",
    "        mask = particle > 0.5\n",
    "        if sum(mask) == 0: return 0\n",
    "        return cross_val_score(LogisticRegression(), X[:,mask], y, \n",
    "                             cv=3, scoring='accuracy').mean()\n",
    "\n",
    "class GWOFeatureSelector:\n",
    "    def __init__(self, n_wolves=20, iterations=50):\n",
    "        self.n_wolves = n_wolves\n",
    "        self.iterations = iterations\n",
    "        self.best_features = None\n",
    "        \n",
    "    def optimize(self, X, y):\n",
    "        n_features = X.shape[1]\n",
    "        wolves = np.random.rand(self.n_wolves, n_features)\n",
    "        alpha = beta = delta = None\n",
    "        alpha_score = beta_score = delta_score = -np.inf\n",
    "        \n",
    "        for _ in range(self.iterations):\n",
    "            scores = [self._fitness(X, y, wolf) for wolf in wolves]\n",
    "            for i, score in enumerate(scores):\n",
    "                if score > alpha_score:\n",
    "                    alpha_score, beta_score, delta_score = score, alpha_score, beta_score\n",
    "                    alpha, beta, delta = wolves[i].copy(), alpha, beta\n",
    "                elif score > beta_score:\n",
    "                    beta_score, delta_score = score, beta_score\n",
    "                    beta, delta = wolves[i].copy(), beta\n",
    "                elif score > delta_score:\n",
    "                    delta_score = score\n",
    "                    delta = wolves[i].copy()\n",
    "                    \n",
    "            a = 2 - 2*(_/self.iterations)\n",
    "            for i in range(self.n_wolves):\n",
    "                A1, A2, A3 = a*(2*np.random.rand(3)-1)\n",
    "                D_alpha = np.abs(A1*alpha - wolves[i])\n",
    "                D_beta = np.abs(A2*beta - wolves[i])\n",
    "                D_delta = np.abs(A3*delta - wolves[i])\n",
    "                X1 = alpha - A1*D_alpha\n",
    "                X2 = beta - A2*D_beta\n",
    "                X3 = delta - A3*D_delta\n",
    "                wolves[i] = (X1 + X2 + X3)/3\n",
    "                \n",
    "        self.best_features = alpha > 0.5\n",
    "        return self.best_features\n",
    "    \n",
    "    def _fitness(self, X, y, wolf):\n",
    "        mask = wolf > 0.5\n",
    "        if sum(mask) == 0: return 0\n",
    "        return cross_val_score(LogisticRegression(), X[:,mask], y,\n",
    "                             cv=3, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% -------- 3. Enhanced Feature Extraction --------\n",
    "class DentalFeatureExtractor:\n",
    "    def __init__(self):\n",
    "        self.hog_params = {\n",
    "            'orientations': 9,\n",
    "            'pixels_per_cell': (32, 32),\n",
    "            'cells_per_block': (2, 2)\n",
    "        }\n",
    "        \n",
    "    def extract_features(self, img):\n",
    "        img_resized = resize(img, IMG_SIZE, anti_aliasing=True)\n",
    "        \n",
    "        # HOG Features\n",
    "        hog = feature.hog(img_resized, **self.hog_params)\n",
    "        \n",
    "        # GLCM Features\n",
    "        glcm = graycomatrix((img_resized*255).astype(np.uint8), \n",
    "                           distances=[1,3], angles=[0, np.pi/4, np.pi/2],\n",
    "                           symmetric=True, normed=True)\n",
    "        contrast = graycoprops(glcm, 'contrast').ravel()\n",
    "        dissimilarity = graycoprops(glcm, 'dissimilarity').ravel()\n",
    "        homogeneity = graycoprops(glcm, 'homogeneity').ravel()\n",
    "        energy = graycoprops(glcm, 'energy').ravel()\n",
    "        \n",
    "        # Gabor Features\n",
    "        gabor_feats = []\n",
    "        for freq in [0.1, 0.3, 0.5]:\n",
    "            for theta in np.linspace(0, np.pi, 4):\n",
    "                real, _ = gabor(img_resized, frequency=freq, theta=theta)\n",
    "                gabor_feats.extend([real.mean(), real.std()])\n",
    "                \n",
    "        return np.concatenate([hog, contrast, dissimilarity,\n",
    "                              homogeneity, energy, gabor_feats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'train/female'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(features), np\u001b[38;5;241m.\u001b[39marray(labels)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Load datasets\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m X_train, y_train \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m X_valid, y_valid \u001b[38;5;241m=\u001b[39m load_data(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     17\u001b[0m X_test, y_test \u001b[38;5;241m=\u001b[39m load_data(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[5], line 8\u001b[0m, in \u001b[0;36mload_data\u001b[1;34m(folder)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m TARGET_NAMES:\n\u001b[0;32m      7\u001b[0m     path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfolder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m      9\u001b[0m         img \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, as_gray\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     10\u001b[0m         features\u001b[38;5;241m.\u001b[39mappend(extractor\u001b[38;5;241m.\u001b[39mextract_features(img))\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'train/female'"
     ]
    }
   ],
   "source": [
    "#%% -------- 4. Data Pipeline --------\n",
    "import os\n",
    "def load_data(folder):\n",
    "    extractor = DentalFeatureExtractor()\n",
    "    features, labels = [], []\n",
    "    for label in TARGET_NAMES:\n",
    "        path = f\"{folder}/{label.lower()}\"\n",
    "        for file in os.listdir(path):\n",
    "            img = io.imread(f\"{path}/{file}\", as_gray=True)\n",
    "            features.append(extractor.extract_features(img))\n",
    "            labels.append(label)\n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "# Load datasets\n",
    "X_train, y_train = load_data(\"train\")\n",
    "X_valid, y_valid = load_data(\"val\")\n",
    "X_test, y_test = load_data(\"test\")\n",
    "\n",
    "# Combine and balance data\n",
    "X_full = np.vstack([X_train, X_valid])\n",
    "y_full = np.concatenate([y_train, y_valid])\n",
    "X_full, y_full = SMOTE().fit_resample(X_full, y_full)\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "y_enc = le.fit_transform(y_full)\n",
    "y_test_enc = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% -------- 5. Feature Selection --------\n",
    "# Optimize with PSO\n",
    "pso = PSOFeatureSelector(n_particles=30, iterations=50)\n",
    "selected_mask = pso.optimize(X_full, y_enc)\n",
    "X_selected = X_full[:, selected_mask]\n",
    "print(f\"Selected {sum(selected_mask)} features from {X_full.shape[1]}\")\n",
    "\n",
    "# Optional: Combine with GWO\n",
    "gwo = GWOFeatureSelector(n_wolves=30, iterations=50)\n",
    "selected_mask = gwo.optimize(X_selected, y_enc)\n",
    "X_selected = X_selected[:, selected_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% -------- 6. Optimized Model Pipeline --------\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA(n_components=0.95)),\n",
    "    ('clf', LogisticRegression(class_weight='balanced', solver='saga',\n",
    "                              max_iter=2000, penalty='l2', C=0.1))\n",
    "])\n",
    "\n",
    "# Cross-validation\n",
    "cv_scores = cross_val_score(pipeline, X_selected, y_enc, \n",
    "                           cv=KFold(5, shuffle=True), scoring='accuracy')\n",
    "print(f\"CV Accuracy: {cv_scores.mean():.2%} ± {cv_scores.std():.2%}\")\n",
    "\n",
    "# Final training\n",
    "pipeline.fit(X_selected, y_enc)\n",
    "test_pred = pipeline.predict(X_test[:, selected_mask])\n",
    "test_proba = pipeline.predict_proba(X_test[:, selected_mask])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% -------- 7. Evaluation & Visualization --------\n",
    "print(f\"\\nTest Accuracy: {accuracy_score(y_test_enc, test_pred):.2%}\")\n",
    "print(f\"AUC-ROC: {roc_auc_score(y_test_enc, test_proba):.2%}\")\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(121)\n",
    "sns.heatmap(confusion_matrix(y_test_enc, test_pred), \n",
    "            annot=True, fmt='d', cmap='Blues', xticklabels=TARGET_NAMES,\n",
    "            yticklabels=TARGET_NAMES)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "\n",
    "plt.subplot(122)\n",
    "fpr, tpr, _ = roc_curve(y_test_enc, test_proba)\n",
    "plt.plot(fpr, tpr, label=f'AUC = {roc_auc_score(y_test_enc, test_proba):.2f}')\n",
    "plt.plot([0,1], [0,1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% -------- 9. Model Saving & Inference --------\n",
    "joblib.dump({\n",
    "    'model': pipeline,\n",
    "    'feature_selector': pso,\n",
    "    'encoder': le,\n",
    "    'feature_mask': selected_mask\n",
    "}, 'optimized_dental_model.pkl')\n",
    "\n",
    "def predict_gender(image_path):\n",
    "    assets = joblib.load('enhanced_dental_model.pkl')\n",
    "    img = io.imread(image_path, as_gray=True)\n",
    "    features = assets['extractor'].extract_features(img)\n",
    "    proba = assets['model'].predict_proba([features])[0]\n",
    "    label = assets['encoder'].inverse_transform([np.argmax(proba)])[0]\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title(f\"Predicted: {label}\\nConfidence: {max(proba):.1%}\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.barh(TARGET_NAMES, proba, color=['pink', 'blue'])\n",
    "    plt.title(\"Class Probabilities\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return label, proba\n",
    "\n",
    "# Example usage\n",
    "test_image = \"D:\\\\level4__semester1\\\\AI-Based\\\\AI-Driven Gender Classification Using Panoramic Dental X-Rays\\Radiographs\\\\test\\\\male\\\\male.447.JPG\"\n",
    "predict_gender(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% -------- 9. Model Saving & Inference --------\n",
    "joblib.dump({\n",
    "    'model': pipeline,\n",
    "    'feature_selector': pso,\n",
    "    'encoder': le,\n",
    "    'feature_mask': selected_mask\n",
    "}, 'optimized_dental_model.pkl')\n",
    "\n",
    "def predict_gender(image_path):\n",
    "    assets = joblib.load('enhanced_dental_model.pkl')\n",
    "    img = io.imread(image_path, as_gray=True)\n",
    "    features = assets['extractor'].extract_features(img)\n",
    "    proba = assets['model'].predict_proba([features])[0]\n",
    "    label = assets['encoder'].inverse_transform([np.argmax(proba)])[0]\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title(f\"Predicted: {label}\\nConfidence: {max(proba):.1%}\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.barh(TARGET_NAMES, proba, color=['pink', 'blue'])\n",
    "    plt.title(\"Class Probabilities\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return label, proba\n",
    "\n",
    "# Example usage\n",
    "test_image = \"D:\\\\level4__semester1\\\\AI-Based\\AI-Driven Gender Classification Using Panoramic Dental X-Rays\\\\Radiographs\\\\test\\\\female\\\\female.457.JPG\"\n",
    "predict_gender(test_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
