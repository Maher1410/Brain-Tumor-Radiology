{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% -------- 1. Imports & Configuration --------\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import joblib\n",
    "import seaborn as sns\n",
    "from skimage import io, feature\n",
    "from skimage.transform import resize\n",
    "from skimage.filters import gabor\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import (classification_report, confusion_matrix,\n",
    "                           roc_curve, roc_auc_score, accuracy_score)\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% -------- 2. Configuration --------\n",
    "IMG_SIZE = (650, 325)  # Reduced size for computational efficiency\n",
    "TARGET_NAMES = ['female', 'male']\n",
    "DATA_PATHS = {\n",
    "    'train': \"D:\\\\level4__semester1\\\\AI-Based\\\\AI-Driven Gender Classification Using Panoramic Dental X-Rays\\\\Radiographs\\\\train\",\n",
    "    'valid': \"D:\\\\level4__semester1\\\\AI-Based\\\\AI-Driven Gender Classification Using Panoramic Dental X-Rays\\\\Radiographs\\\\val\",\n",
    "    'test': \"D:\\\\level4__semester1\\\\AI-Based\\\\AI-Driven Gender Classification Using Panoramic Dental X-Rays\\\\Radiographs\\\\test\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% -------- 2. Metaheuristic Feature Selectors --------\n",
    "class PSOFeatureSelector:\n",
    "    def __init__(self, n_particles=20, iterations=50, phi1=1.5, phi2=1.5):\n",
    "        self.n_particles = n_particles\n",
    "        self.iterations = iterations\n",
    "        self.phi1 = phi1\n",
    "        self.phi2 = phi2\n",
    "        self.best_features = None\n",
    "        \n",
    "    def optimize(self, X, y):\n",
    "        n_features = X.shape[1]\n",
    "        particles = np.random.rand(self.n_particles, n_features)\n",
    "        velocities = np.zeros_like(particles)\n",
    "        pbest = particles.copy()\n",
    "        pbest_scores = np.zeros(self.n_particles)\n",
    "        gbest = None\n",
    "        gbest_score = 0\n",
    "        \n",
    "        for i in range(self.n_particles):\n",
    "            score = self._fitness(X, y, particles[i])\n",
    "            pbest_scores[i] = score\n",
    "            if score > gbest_score:\n",
    "                gbest_score = score\n",
    "                gbest = particles[i].copy()\n",
    "                \n",
    "        for _ in range(self.iterations):\n",
    "            for i in range(self.n_particles):\n",
    "                r1, r2 = np.random.rand(2)\n",
    "                velocities[i] += self.phi1*r1*(pbest[i] - particles[i]) + \\\n",
    "                                self.phi2*r2*(gbest - particles[i])\n",
    "                particles[i] = 1/(1+np.exp(-velocities[i]))\n",
    "                \n",
    "                score = self._fitness(X, y, particles[i])\n",
    "                if score > pbest_scores[i]:\n",
    "                    pbest_scores[i] = score\n",
    "                    pbest[i] = particles[i].copy()\n",
    "                    if score > gbest_score:\n",
    "                        gbest_score = score\n",
    "                        gbest = particles[i].copy()\n",
    "                        \n",
    "        self.best_features = gbest > 0.5\n",
    "        return self.best_features\n",
    "    \n",
    "    def _fitness(self, X, y, particle):\n",
    "        mask = particle > 0.5\n",
    "        if sum(mask) == 0: return 0\n",
    "        return cross_val_score(LogisticRegression(), X[:,mask], y, \n",
    "                             cv=3, scoring='accuracy').mean()\n",
    "\n",
    "class GWOFeatureSelector:\n",
    "    def __init__(self, n_wolves=20, iterations=50):\n",
    "        self.n_wolves = n_wolves\n",
    "        self.iterations = iterations\n",
    "        self.best_features = None\n",
    "        \n",
    "    def optimize(self, X, y):\n",
    "        n_features = X.shape[1]\n",
    "        wolves = np.random.rand(self.n_wolves, n_features)\n",
    "        alpha = beta = delta = None\n",
    "        alpha_score = beta_score = delta_score = -np.inf\n",
    "        \n",
    "        for _ in range(self.iterations):\n",
    "            scores = [self._fitness(X, y, wolf) for wolf in wolves]\n",
    "            for i, score in enumerate(scores):\n",
    "                if score > alpha_score:\n",
    "                    alpha_score, beta_score, delta_score = score, alpha_score, beta_score\n",
    "                    alpha, beta, delta = wolves[i].copy(), alpha, beta\n",
    "                elif score > beta_score:\n",
    "                    beta_score, delta_score = score, beta_score\n",
    "                    beta, delta = wolves[i].copy(), beta\n",
    "                elif score > delta_score:\n",
    "                    delta_score = score\n",
    "                    delta = wolves[i].copy()\n",
    "                    \n",
    "            a = 2 - 2*(_/self.iterations)\n",
    "            for i in range(self.n_wolves):\n",
    "                A1, A2, A3 = a*(2*np.random.rand(3)-1)\n",
    "                D_alpha = np.abs(A1*alpha - wolves[i])\n",
    "                D_beta = np.abs(A2*beta - wolves[i])\n",
    "                D_delta = np.abs(A3*delta - wolves[i])\n",
    "                X1 = alpha - A1*D_alpha\n",
    "                X2 = beta - A2*D_beta\n",
    "                X3 = delta - A3*D_delta\n",
    "                wolves[i] = (X1 + X2 + X3)/3\n",
    "                \n",
    "        self.best_features = alpha > 0.5\n",
    "        return self.best_features\n",
    "    \n",
    "    def _fitness(self, X, y, wolf):\n",
    "        mask = wolf > 0.5\n",
    "        if sum(mask) == 0: return 0\n",
    "        return cross_val_score(LogisticRegression(), X[:,mask], y,\n",
    "                             cv=3, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% -------- 3. Enhanced Feature Extraction --------\n",
    "class DentalFeatureExtractor:\n",
    "    def __init__(self):\n",
    "        self.hog_params = {\n",
    "            'orientations': 9,\n",
    "            'pixels_per_cell': (32, 32),\n",
    "            'cells_per_block': (2, 2)\n",
    "        }\n",
    "        \n",
    "    def extract_features(self, img):\n",
    "        img_resized = resize(img, IMG_SIZE, anti_aliasing=True)\n",
    "        \n",
    "        # HOG Features\n",
    "        hog = feature.hog(img_resized, **self.hog_params)\n",
    "        \n",
    "        # GLCM Features\n",
    "        glcm = graycomatrix((img_resized*255).astype(np.uint8), \n",
    "                           distances=[1,3], angles=[0, np.pi/4, np.pi/2],\n",
    "                           symmetric=True, normed=True)\n",
    "        contrast = graycoprops(glcm, 'contrast').ravel()\n",
    "        dissimilarity = graycoprops(glcm, 'dissimilarity').ravel()\n",
    "        homogeneity = graycoprops(glcm, 'homogeneity').ravel()\n",
    "        energy = graycoprops(glcm, 'energy').ravel()\n",
    "        \n",
    "        # Gabor Features\n",
    "        gabor_feats = []\n",
    "        for freq in [0.1, 0.3, 0.5]:\n",
    "            for theta in np.linspace(0, np.pi, 4):\n",
    "                real, _ = gabor(img_resized, frequency=freq, theta=theta)\n",
    "                gabor_feats.extend([real.mean(), real.std()])\n",
    "                \n",
    "        return np.concatenate([hog, contrast, dissimilarity,\n",
    "                              homogeneity, energy, gabor_feats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% -------- 4. Data Pipeline --------\n",
    "import os\n",
    "def load_data(folder):\n",
    "    extractor = DentalFeatureExtractor()\n",
    "    features, labels = [], []\n",
    "    for label in TARGET_NAMES:\n",
    "        path = f\"{folder}/{label.lower()}\"\n",
    "        for file in os.listdir(path):\n",
    "            img = io.imread(f\"{path}/{file}\", as_gray=True)\n",
    "            features.append(extractor.extract_features(img))\n",
    "            labels.append(label)\n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "# Load datasets\n",
    "X_train, y_train = load_data(DATA_PATHS['train'])\n",
    "X_valid, y_valid = load_data(DATA_PATHS['valid'])\n",
    "X_test, y_test = load_data(DATA_PATHS['test'])\n",
    "\n",
    "# Combine and balance data\n",
    "X_full = np.vstack([X_train, X_valid])\n",
    "y_full = np.concatenate([y_train, y_valid])\n",
    "X_full, y_full = SMOTE().fit_resample(X_full, y_full)\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "y_enc = le.fit_transform(y_full)\n",
    "y_test_enc = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 3048 features from 6204\n"
     ]
    }
   ],
   "source": [
    "#%% -------- 5. Feature Selection --------\n",
    "# Optimize with PSO\n",
    "pso = PSOFeatureSelector(n_particles=30, iterations=50)\n",
    "selected_mask = pso.optimize(X_full, y_enc)\n",
    "X_selected = X_full[:, selected_mask]\n",
    "print(f\"Selected {sum(selected_mask)} features from {X_full.shape[1]}\")\n",
    "\n",
    "# Optional: Combine with GWO\n",
    "gwo = GWOFeatureSelector(n_wolves=30, iterations=50)\n",
    "selected_mask = gwo.optimize(X_selected, y_enc)\n",
    "X_selected = X_selected[:, selected_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy: 94.90% ± 1.03%\n"
     ]
    },
    {
     "ename": "NotFittedError",
     "evalue": "This StandardScaler instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCV Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcv_scores\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2%\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ± \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcv_scores\u001b[38;5;241m.\u001b[39mstd()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2%\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Ensure `X_test` undergoes the same transformation\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m X_test_transformed \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnamed_steps\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mscaler\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Standardization\u001b[39;00m\n\u001b[0;32m     16\u001b[0m X_test_pca \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mnamed_steps[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpca\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtransform(X_test_transformed)  \u001b[38;5;66;03m# Apply PCA\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 157\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    160\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    162\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    163\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:1003\u001b[0m, in \u001b[0;36mStandardScaler.transform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m    988\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    989\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Perform standardization by centering and scaling.\u001b[39;00m\n\u001b[0;32m    990\u001b[0m \n\u001b[0;32m    991\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1001\u001b[0m \u001b[38;5;124;03m        Transformed array.\u001b[39;00m\n\u001b[0;32m   1002\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1003\u001b[0m     \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1005\u001b[0m     copy \u001b[38;5;241m=\u001b[39m copy \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[0;32m   1006\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m   1007\u001b[0m         X,\n\u001b[0;32m   1008\u001b[0m         reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1012\u001b[0m         force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1013\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1461\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1458\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not an estimator instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (estimator))\n\u001b[0;32m   1460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_fitted(estimator, attributes, all_or_any):\n\u001b[1;32m-> 1461\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This StandardScaler instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "#%% -------- 6. Optimized Model Pipeline --------\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA(n_components=0.95)),\n",
    "    ('clf', LogisticRegression(class_weight='balanced', solver='saga',\n",
    "                              max_iter=2000, penalty='l2', C=0.1))\n",
    "])\n",
    "\n",
    "# Cross-validation\n",
    "cv_scores = cross_val_score(pipeline, X_selected, y_enc, \n",
    "                           cv=KFold(5, shuffle=True), scoring='accuracy')\n",
    "print(f\"CV Accuracy: {cv_scores.mean():.2%} ± {cv_scores.std():.2%}\")\n",
    "\n",
    "# Ensure `X_test` undergoes the same transformation\n",
    "X_test_transformed = pipeline.named_steps['scaler'].transform(X_test)  # Standardization\n",
    "X_test_pca = pipeline.named_steps['pca'].transform(X_test_transformed)  # Apply PCA\n",
    "\n",
    "# Make predictions\n",
    "test_pred = pipeline.named_steps['clf'].predict(X_test_pca)\n",
    "test_proba = pipeline.named_steps['clf'].predict_proba(X_test_pca)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% -------- 7. Evaluation & Visualization --------\n",
    "print(f\"\\nTest Accuracy: {accuracy_score(y_test_enc, test_pred):.2%}\")\n",
    "print(f\"AUC-ROC: {roc_auc_score(y_test_enc, test_proba):.2%}\")\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(121)\n",
    "sns.heatmap(confusion_matrix(y_test_enc, test_pred), \n",
    "            annot=True, fmt='d', cmap='Blues', xticklabels=TARGET_NAMES,\n",
    "            yticklabels=TARGET_NAMES)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "\n",
    "plt.subplot(122)\n",
    "fpr, tpr, _ = roc_curve(y_test_enc, test_proba)\n",
    "plt.plot(fpr, tpr, label=f'AUC = {roc_auc_score(y_test_enc, test_proba):.2f}')\n",
    "plt.plot([0,1], [0,1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% -------- 9. Model Saving & Inference --------\n",
    "joblib.dump({\n",
    "    'model': pipeline,\n",
    "    'feature_selector': pso,\n",
    "    'encoder': le,\n",
    "    'feature_mask': selected_mask\n",
    "}, 'optimized_dental_model.pkl')\n",
    "\n",
    "def predict_gender(image_path):\n",
    "    assets = joblib.load('enhanced_dental_model.pkl')\n",
    "    img = io.imread(image_path, as_gray=True)\n",
    "    features = assets['extractor'].extract_features(img)\n",
    "    proba = assets['model'].predict_proba([features])[0]\n",
    "    label = assets['encoder'].inverse_transform([np.argmax(proba)])[0]\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title(f\"Predicted: {label}\\nConfidence: {max(proba):.1%}\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.barh(TARGET_NAMES, proba, color=['pink', 'blue'])\n",
    "    plt.title(\"Class Probabilities\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return label, proba\n",
    "\n",
    "# Example usage\n",
    "test_image = \"D:\\\\level4__semester1\\\\AI-Based\\\\AI-Driven Gender Classification Using Panoramic Dental X-Rays\\Radiographs\\\\test\\\\male\\\\male.447.JPG\"\n",
    "predict_gender(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% -------- 9. Model Saving & Inference --------\n",
    "joblib.dump({\n",
    "    'model': pipeline,\n",
    "    'feature_selector': pso,\n",
    "    'encoder': le,\n",
    "    'feature_mask': selected_mask\n",
    "}, 'optimized_dental_model.pkl')\n",
    "\n",
    "def predict_gender(image_path):\n",
    "    assets = joblib.load('enhanced_dental_model.pkl')\n",
    "    img = io.imread(image_path, as_gray=True)\n",
    "    features = assets['extractor'].extract_features(img)\n",
    "    proba = assets['model'].predict_proba([features])[0]\n",
    "    label = assets['encoder'].inverse_transform([np.argmax(proba)])[0]\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title(f\"Predicted: {label}\\nConfidence: {max(proba):.1%}\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.barh(TARGET_NAMES, proba, color=['pink', 'blue'])\n",
    "    plt.title(\"Class Probabilities\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return label, proba\n",
    "\n",
    "# Example usage\n",
    "test_image = \"D:\\\\level4__semester1\\\\AI-Based\\AI-Driven Gender Classification Using Panoramic Dental X-Rays\\\\Radiographs\\\\test\\\\female\\\\female.457.JPG\"\n",
    "predict_gender(test_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
