{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# %% Cell 1: Enhanced Imports and Setup\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from transformers import ViTConfig\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (roc_curve, auc, confusion_matrix, \n",
    "                            ConfusionMatrixDisplay, classification_report)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 2: Enhanced Dataset Class with Oversampling\n",
    "class DyslexiaDataset(Dataset):\n",
    "    def __init__(self, root_dir, sample_size=7000, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.samples = []\n",
    "        \n",
    "        # Collect PNG files\n",
    "        png_files = []\n",
    "        for foldername, _, filenames in os.walk(root_dir):\n",
    "            png_files.extend([\n",
    "                os.path.join(foldername, f) \n",
    "                for f in filenames if f.lower().endswith('.png')\n",
    "            ])\n",
    "        \n",
    "        if not png_files:\n",
    "            raise ValueError(f\"No PNG files found in {root_dir}\")\n",
    "\n",
    "        # Random sampling\n",
    "        sample_size = min(sample_size, len(png_files))\n",
    "        np.random.seed(42)\n",
    "        self.samples = np.random.choice(png_files, sample_size, False)\n",
    "        \n",
    "        # Create labels\n",
    "        self.labels = np.array([\n",
    "            1 if re.search(r'hsf_[7-9]', path) else 0 \n",
    "            for path in self.samples\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.samples[idx]).convert('RGB')\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_transforms():\n",
    "    from torchvision import transforms as T  # Rename the import\n",
    "    \n",
    "    return {\n",
    "        'train': T.Compose([\n",
    "            T.RandomRotation(15),\n",
    "            T.RandomAffine(0, shear=15),\n",
    "            T.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "            T.RandomHorizontalFlip(),\n",
    "            T.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        'test': T.Compose([\n",
    "            T.Resize(256),\n",
    "            T.CenterCrop(224),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 4: Feature Extractor\n",
    "class EnhancedFeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(128, 256, 3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((14, 14))\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x)  # (B, 256, 14, 14)\n",
    "        return x.flatten(2).transpose(1, 2)  # (B, 196, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 5: Enhanced Transformer Model\n",
    "class DyslexiaTransformer(nn.Module):\n",
    "    def __init__(self, num_features=256, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.config = ViTConfig(\n",
    "            hidden_size=512,\n",
    "            num_hidden_layers=6,\n",
    "            num_attention_heads=16,\n",
    "            intermediate_size=1024,\n",
    "            hidden_dropout_prob=0.2\n",
    "        )\n",
    "        \n",
    "        # Projection layer\n",
    "        self.proj = nn.Linear(num_features, self.config.hidden_size)\n",
    "        \n",
    "        # Positional embeddings\n",
    "        self.pos_embed = nn.Parameter(\n",
    "            torch.zeros(1, 197, self.config.hidden_size))\n",
    "        nn.init.trunc_normal_(self.pos_embed, std=0.02)\n",
    "        \n",
    "        # CLS token\n",
    "        self.cls_token = nn.Parameter(torch.zeros(1, 1, self.config.hidden_size))\n",
    "        \n",
    "        # Transformer encoder\n",
    "        self.encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(\n",
    "                d_model=self.config.hidden_size,\n",
    "                nhead=self.config.num_attention_heads,\n",
    "                dim_feedforward=self.config.intermediate_size,\n",
    "                dropout=self.config.hidden_dropout_prob,\n",
    "                batch_first=True\n",
    "            ),\n",
    "            num_layers=self.config.num_hidden_layers\n",
    "        )\n",
    "        \n",
    "        # Classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.LayerNorm(self.config.hidden_size),\n",
    "            nn.Linear(self.config.hidden_size, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Project features\n",
    "        x = self.proj(x)  # (B, 196, 512)\n",
    "        \n",
    "        # Add CLS token\n",
    "        cls_tokens = self.cls_token.expand(x.size(0), -1, -1)\n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "        \n",
    "        # Add positional embeddings\n",
    "        x += self.pos_embed\n",
    "        \n",
    "        # Transformer encoder\n",
    "        x = self.encoder(x)\n",
    "        \n",
    "        # Classify using CLS token\n",
    "        return self.classifier(x[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 6: Focal Loss Implementation\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.8, gamma=2.0):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        loss = self.alpha * (1 - pt)**self.gamma * ce_loss\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 7: Training Infrastructure\n",
    "class Trainer:\n",
    "    def __init__(self, model, extractor, device):\n",
    "        self.model = model\n",
    "        self.extractor = extractor\n",
    "        self.device = device\n",
    "        \n",
    "        # Metrics tracking\n",
    "        self.train_loss = []\n",
    "        self.val_metrics = {\n",
    "            'accuracy': [], 'roc_auc': [], \n",
    "            'precision': [], 'recall': []}\n",
    "\n",
    "    def train_epoch(self, loader, optimizer, scheduler):\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        for inputs, labels in loader:\n",
    "            inputs = inputs.to(self.device, non_blocking=True)\n",
    "            labels = labels.to(self.device, non_blocking=True)\n",
    "            \n",
    "            # Forward pass\n",
    "            features = self.extractor(inputs)\n",
    "            outputs = self.model(features)\n",
    "            \n",
    "            # Loss calculation\n",
    "            loss = self.criterion(outputs, labels)\n",
    "            \n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        scheduler.step()\n",
    "        return total_loss / len(loader)\n",
    "\n",
    "    def evaluate(self, loader):\n",
    "        self.model.eval()\n",
    "        all_preds = []\n",
    "        all_probs = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in loader:\n",
    "                inputs = inputs.to(self.device)\n",
    "                labels = labels.cpu().numpy()\n",
    "                \n",
    "                features = self.extractor(inputs)\n",
    "                outputs = self.model(features)\n",
    "                probs = F.softmax(outputs, dim=1).cpu().numpy()\n",
    "                \n",
    "                all_probs.extend(probs[:, 1])\n",
    "                all_preds.extend(np.argmax(probs, axis=1))\n",
    "                all_labels.extend(labels)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy = np.mean(np.array(all_preds) == np.array(all_labels))\n",
    "        fpr, tpr, _ = roc_curve(all_labels, all_probs)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        tn, fp, fn, tp = confusion_matrix(all_labels, all_preds).ravel()\n",
    "        precision = tp / (tp + fp + 1e-8)\n",
    "        recall = tp / (tp + fn + 1e-8)\n",
    "        \n",
    "        return {\n",
    "            'accuracy': accuracy,\n",
    "            'roc_auc': roc_auc,\n",
    "            'precision': precision,\n",
    "            'recall': recall\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 20184, 20628, 1532, 24548) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:1132\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1132\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\multiprocessing\\queues.py:114\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll(timeout):\n\u001b[1;32m--> 114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "\u001b[1;31mEmpty\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 91\u001b[0m\n\u001b[0;32m     88\u001b[0m best_roc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m20\u001b[39m):\n\u001b[0;32m     90\u001b[0m     \u001b[38;5;66;03m# Training\u001b[39;00m\n\u001b[1;32m---> 91\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     92\u001b[0m     trainer\u001b[38;5;241m.\u001b[39mtrain_loss\u001b[38;5;241m.\u001b[39mappend(loss)\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;66;03m# Evaluation\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[7], line 18\u001b[0m, in \u001b[0;36mTrainer.train_epoch\u001b[1;34m(self, loader, optimizer, scheduler)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m     16\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 18\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:1328\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[0;32m   1327\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1328\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1329\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1330\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[0;32m   1331\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:1294\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1290\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[0;32m   1291\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[0;32m   1292\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1293\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m-> 1294\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1295\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[0;32m   1296\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:1145\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(failed_workers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1144\u001b[0m     pids_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(w\u001b[38;5;241m.\u001b[39mpid) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m failed_workers)\n\u001b[1;32m-> 1145\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataLoader worker (pid(s) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpids_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) exited unexpectedly\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, queue\u001b[38;5;241m.\u001b[39mEmpty):\n\u001b[0;32m   1147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 20184, 20628, 1532, 24548) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "# %% Cell 8: Main Execution (Corrected)\n",
    "if __name__ == \"__main__\":\n",
    "    # Data preparation\n",
    "    data_transforms = create_transforms()  # Changed variable name\n",
    "    full_dataset = DyslexiaDataset(\n",
    "        root_dir='D:\\\\Dyslexia\\\\by_class\\\\by_class',\n",
    "        sample_size=100,\n",
    "        transform=None\n",
    "    )\n",
    "    \n",
    "    # Stratified split\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "    train_idx, test_idx = next(sss.split(full_dataset.samples, full_dataset.labels))\n",
    "    \n",
    "    # Apply transforms\n",
    "    class TransformSubset(Dataset):\n",
    "        def __init__(self, subset, transform):\n",
    "            self.subset = subset\n",
    "            self.transform = transform\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            img, label = self.subset[idx]\n",
    "            if self.transform:\n",
    "                img = self.transform(img)\n",
    "            return img, label\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.subset)\n",
    "    \n",
    "    # Oversampling\n",
    "    ros = RandomOverSampler(random_state=42)\n",
    "    resampled_idx, _ = ros.fit_resample(\n",
    "        train_idx.reshape(-1, 1), full_dataset.labels[train_idx])\n",
    "    train_idx = resampled_idx.squeeze()\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = TransformSubset(\n",
    "        Subset(full_dataset, train_idx), data_transforms['train'])  # Use new name\n",
    "    \n",
    "    test_dataset = TransformSubset(\n",
    "        Subset(full_dataset, test_idx), data_transforms['test'])  # Use new name\n",
    "\n",
    "    # Create data loaders (CRUCIAL FIX)\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=32,\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=32,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    # Initialize models\n",
    "    feature_extractor = EnhancedFeatureExtractor().to(device)\n",
    "    model = DyslexiaTransformer(num_features=256).to(device)\n",
    "    \n",
    "    # Multi-GPU support\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(f\"Using {torch.cuda.device_count()} GPUs!\")\n",
    "        feature_extractor = nn.DataParallel(feature_extractor)\n",
    "        model = nn.DataParallel(model)\n",
    "\n",
    "    # Training setup\n",
    "    optimizer = torch.optim.AdamW([\n",
    "        {'params': feature_extractor.parameters(), 'lr': 1e-4},\n",
    "        {'params': model.parameters(), 'lr': 5e-5}\n",
    "    ], weight_decay=0.01)\n",
    "    \n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer,\n",
    "        max_lr=1e-3,\n",
    "        steps_per_epoch=len(train_loader),\n",
    "        epochs=20\n",
    "    )\n",
    "    \n",
    "    criterion = FocalLoss(alpha=0.8, gamma=2.0)\n",
    "    trainer = Trainer(model, feature_extractor, device)\n",
    "    trainer.criterion = criterion\n",
    "\n",
    "    # Training loop\n",
    "    best_roc = 0\n",
    "    for epoch in range(20):\n",
    "        # Training\n",
    "        loss = trainer.train_epoch(train_loader, optimizer, scheduler)\n",
    "        trainer.train_loss.append(loss)\n",
    "        \n",
    "        # Evaluation\n",
    "        metrics = trainer.evaluate(test_loader)\n",
    "        for k in trainer.val_metrics:\n",
    "            trainer.val_metrics[k].append(metrics[k])\n",
    "        \n",
    "        # Save best model\n",
    "        if metrics['roc_auc'] > best_roc:\n",
    "            best_roc = metrics['roc_auc']\n",
    "            torch.save({\n",
    "                'extractor': feature_extractor.state_dict(),\n",
    "                'model': model.state_dict(),\n",
    "            }, 'best_model.pth')\n",
    "        \n",
    "        # Print progress\n",
    "        print(f\"Epoch {epoch+1}/20\")\n",
    "        print(f\"Train Loss: {loss:.4f} | Val Acc: {metrics['accuracy']:.4f}\")\n",
    "        print(f\"ROC AUC: {metrics['roc_auc']:.4f} | Precision: {metrics['precision']:.4f} | Recall: {metrics['recall']:.4f}\")\n",
    "        print(\"-----------------------------------\")\n",
    "\n",
    "    # Final evaluation\n",
    "    print(\"\\nBest Model Performance:\")\n",
    "    model.load_state_dict(torch.load('best_model.pth')['model'])\n",
    "    final_metrics = trainer.evaluate(test_loader)\n",
    "    print(classification_report(\n",
    "        final_metrics['true_labels'],\n",
    "        final_metrics['predictions'],\n",
    "        target_names=['Non-Dyslexic', 'Dyslexic']\n",
    "    ))\n",
    "\n",
    "    # Plot metrics\n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(trainer.train_loss, label='Train Loss')\n",
    "    plt.title('Training Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(trainer.val_metrics['accuracy'], label='Accuracy')\n",
    "    plt.plot(trainer.val_metrics['roc_auc'], label='ROC AUC')\n",
    "    plt.title('Validation Metrics')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
